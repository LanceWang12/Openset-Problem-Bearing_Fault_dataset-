{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch_tool.trainer import TorchModule"
   ]
  },
  {
   "source": [
    "## Define bearing model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BearingNet(TorchModule):\n",
    "    def __init__(self, in_channels = 1, encode_size = 128, use_gpu = True, gpu_id = 0):\n",
    "        super().__init__(use_gpu = use_gpu, gpu_id = gpu_id)\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels, out_channels = 20, kernel_size = 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "\n",
    "            nn.Conv2d(in_channels = 20, out_channels = 16, kernel_size = 4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2),\n",
    "\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(144),\n",
    "            nn.Linear(144, 132),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(132),\n",
    "            nn.Linear(132, encode_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.TripletMarginLoss()\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.cnn(img)\n",
    "        out = self.fully_connected(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "source": [
    "## Read model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Read facenet -------\n",
    "import torch\n",
    "from dataset import get_pattern\n",
    "model = BearingNet()\n",
    "model_path = './checkpoint/model_16_1.41.pth'\n",
    "params = torch.load(model_path)\n",
    "model.load_state_dict(params)\n",
    "\n",
    "# -------- Read random forest -------\n",
    "from joblib import load\n",
    "RF = load('./checkpoint/RF_0.87.pth')\n",
    "\n",
    "# ------- Read pattern vector -------\n",
    "PatternVector = load('./data/Pattern_Vector/PatternVector.pth')"
   ]
  },
  {
   "source": [
    "## Get encoding vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_dict\n",
    "\n",
    "test_dict = get_dict(path = './data/Image/test')\n",
    "class_lst = ['Normal', 'Inner_break', 'Outer_break', 'Ball']\n",
    "label_lst = []\n",
    "vec_lst = torch.zeros(1, 128)\n",
    "count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cla in class_lst:\n",
    "        length = test_dict[cla].shape[0]\n",
    "        label_lst += [count for _ in range(length)]\n",
    "        vec = model(test_dict[cla])\n",
    "        vec_lst = torch.cat([vec_lst, vec], dim = 0)\n",
    "        count += 1\n",
    "\n",
    "vec_lst_torch = vec_lst[1:]\n",
    "vec_lst_np = vec_lst_torch.numpy()\n",
    "label_lst = np.array(label_lst)\n",
    "\n",
    "print(vec_lst_np.shape, label_lst.shape)"
   ]
  },
  {
   "source": [
    "## Facenet test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(label_lst.shape[0])\n",
    "thrs = 1.125\n",
    "for i, vec in enumerate(vec_lst_torch):\n",
    "    count = 0\n",
    "    for key in PatternVector.keys():\n",
    "        dist = torch.sqrt(torch.sum((vec - PatternVector[key]) ** 2))\n",
    "        \n",
    "        if dist < thrs:\n",
    "            count += 1\n",
    "            break\n",
    "    \n",
    "    if count == 0:\n",
    "        pred[i] = 3\n",
    "    else:\n",
    "        pred[i] = RF.predict(vec_lst_np[i].reshape(1, 128))[0]"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score    support\n",
    "\n",
    "           0       0.71      0.61      0.68        100\n",
    "           1       0.52      0.59      0.56        103\n",
    "           2       0.55      0.58      0.59        155\n",
    "           3       0.49      0.43      0.47        118\n",
    "\n",
    "    accuracy                           0.53        476\n",
    "   macro avg       0.88      0.88      0.54        476\n",
    "weighted avg       0.89      0.87      0.55        476"
   ]
  }
 ]
}