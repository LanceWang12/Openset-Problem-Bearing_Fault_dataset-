{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_header import BearingNet\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------\n| The model use Cuda:0 to train. |\n---------------------------------- \n\n"
     ]
    }
   ],
   "source": [
    "# ------- Read facenet -------\n",
    "import torch\n",
    "\n",
    "encode_size = 40\n",
    "model = BearingNet(encode_size=encode_size)\n",
    "model_path = './checkpoint/model_30_0.31.pth'\n",
    "params = torch.load(model_path)\n",
    "model.load_state_dict(params)\n",
    "model.eval()\n",
    "\n",
    "# -------- Read random forest -------\n",
    "from joblib import load\n",
    "RF = load('./checkpoint/RF.pth')\n",
    "\n",
    "# ------- Read pattern vector -------\n",
    "PatternVector = load('./data/Pattern_Vector/PatternVector.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get encoding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(476, 40) (476,)\n"
     ]
    }
   ],
   "source": [
    "from project_header import get_dict\n",
    "\n",
    "test_dict = get_dict(path = './data/Image/test')\n",
    "class_lst = ['Normal', 'Inner_break', 'Outer_break', 'Ball']\n",
    "label_lst = []\n",
    "vec_lst = torch.zeros(1, encode_size)\n",
    "count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for cla in class_lst:\n",
    "        length = test_dict[cla].shape[0]\n",
    "        label_lst += [count for _ in range(length)]\n",
    "        vec = model(test_dict[cla])\n",
    "        vec_lst = torch.cat([vec_lst, vec], dim = 0)\n",
    "        count += 1\n",
    "\n",
    "vec_lst_torch = vec_lst[1:]\n",
    "vec_lst_np = vec_lst_torch.numpy()\n",
    "label_lst = np.array(label_lst)\n",
    "\n",
    "print(vec_lst_np.shape, label_lst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/Vector/x_test.npy', vec_lst)\n",
    "np.save('./data/Vector/y_test.npy', label_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = np.zeros(label_lst.shape[0])\n",
    "thrs = 0.0802\n",
    "for i, vec in enumerate(vec_lst_torch):\n",
    "    count = 0\n",
    "    for key in PatternVector.keys():\n",
    "        dist = torch.sqrt(torch.sum((vec - PatternVector[key]) ** 2).mean())\n",
    "        # print(dist)\n",
    "        if dist < thrs:\n",
    "            count += 1\n",
    "            break\n",
    "    \n",
    "    if count == 0:\n",
    "        pred[i] = 3\n",
    "    else:\n",
    "        pred[i] = RF.predict(vec_lst_np[i].reshape(1, encode_size))[0]\n",
    "    \n",
    "    # if i == 10:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       1.00      0.95      0.97       118\n           1       0.96      0.53      0.68       120\n           2       0.99      0.97      0.98       119\n           3       0.64      0.97      0.77       119\n\n    accuracy                           0.85       476\n   macro avg       0.90      0.85      0.85       476\nweighted avg       0.90      0.85      0.85       476\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_lst, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50bd5474255f82aa829301912ce59e29110123be660cf8d7583f66a20371684"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}